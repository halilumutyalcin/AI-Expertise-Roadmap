{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            6      148             72             35        0  33.6   \n1            1       85             66             29        0  26.6   \n2            8      183             64              0        0  23.3   \n3            1       89             66             23       94  28.1   \n4            0      137             40             35      168  43.1   \n\n   DiabetesPedigreeFunction  Age  Outcome  \n0                     0.627   50        1  \n1                     0.351   31        0  \n2                     0.672   32        1  \n3                     0.167   21        0  \n4                     2.288   33        1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv(\"../Data/diabetes.csv\")\n",
    "df = diabetes.copy()\n",
    "df = df.dropna()\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "XGBoost (eXtreme Gradient Boosting) is a powerful and widely-used machine learning algorithm for both regression and classification problems. It is based on the concept of gradient boosting, which involves building a series of decision trees and combining them in a way that improves the overall accuracy of the model.\n",
    "\n",
    "XGBoost is particularly effective at handling large and complex datasets and is often used in fields such as finance, healthcare, and e-commerce. It is also popular in data science competitions due to its high accuracy and ability to quickly analyze large datasets.\n",
    "\n",
    "One of the key features of XGBoost is its ability to handle missing values and handle them effectively. It also has a variety of parameters that can be fine-tuned to optimize the model's performance.\n",
    "\n",
    "XGBoost is implemented using the gradient boosting decision tree (GBDT) algorithm and is designed to be highly efficient and scalable. It uses a novel tree-based model called a \"boosted tree\" that is trained through an iterative process. At each iteration, the algorithm adds a new tree to the model and adjusts the parameters of the existing trees to improve the overall accuracy of the model.\n",
    "\n",
    "Overall, XGBoost is a powerful and widely-used machine learning algorithm that is effective at handling large and complex datasets and is known for its high accuracy and ability to quickly analyze large datasets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df[\"Outcome\"]\n",
    "X = df.drop(['Outcome'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.30,\n",
    "                                                    random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier().fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7359307359307359"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 576 candidates, totalling 5760 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:   55.2s\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1426 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1953 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2560 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3249 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4018 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4869 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 5760 out of 5760 | elapsed:  7.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:55:09] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'learning_rate': 0.02,\n 'max_depth': 3,\n 'min_samples_split': 2,\n 'n_estimators': 100,\n 'subsample': 0.6}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'n_estimators': [100, 500, 1000, 2000],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'learning_rate': [0.1, 0.01, 0.02, 0.05],\n",
    "    \"min_samples_split\": [2, 5, 10]}\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_cv_model = GridSearchCV(xgb, xgb_params, cv=10, n_jobs=-1, verbose=2)\n",
    "xgb_cv_model.fit(X_train, y_train)\n",
    "xgb_cv_model.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:59:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7575757575757576"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.02,\n",
    "                    max_depth=3,\n",
    "                    min_samples_split=2,\n",
    "                    n_estimators=100,\n",
    "                    subsample=0.6)\n",
    "\n",
    "xgb_tuned = xgb.fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}